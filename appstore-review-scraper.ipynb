{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "709f8b1a-0d3a-43b6-b2e1-e9a48fd1f02c",
   "metadata": {},
   "source": [
    "# Porsche Competetive Scraper\n",
    "## Goal: Scrape the App Store for the My Porsche App & Competitors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b609303-018f-464a-9588-80bb6b59e2da",
   "metadata": {},
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8921ee38-96fb-4551-9e94-8687f19126bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "from itunes_app_scraper.scraper import AppStoreScraper\n",
    "from app_store_scraper import AppStore\n",
    "\n",
    "import datetime as dt\n",
    "from tzlocal import get_localzone\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import math\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902308f7-cb3f-4cf7-bc61-013fda0af647",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download de_core_news_sm  # download spacy trained pipeline for german language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a8226-7b40-456c-a501-1cd2a09fd82a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3767e7e-5312-4500-98dc-a76e9b8512d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_app_list():\n",
    "    \"\"\"\n",
    "    Read file that includes all apps that are to be scraped\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"app_list_updated.csv\", sep=\";\")\n",
    "    df[\"iOS_app_id\"] = df[\"iOS_app_id\"].str.replace(\"id\", \"\").astype(\"int\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_general_app_info(app_list_df):\n",
    "    \"\"\"\n",
    "    Take loaded app list as input and return meta information from the\n",
    "    app store about every app (indicated by app id) in the list.\n",
    "    \"\"\"\n",
    "    scraper = AppStoreScraper()\n",
    "    app_ids = app_list_df[\"iOS_app_id\"]\n",
    "    app_meta_info = list(scraper.get_multiple_app_details(app_ids, country=\"de\"))\n",
    "    app_meta_info_df = pd.DataFrame(app_meta_info)\n",
    "    return app_meta_info_df\n",
    "\n",
    "\n",
    "def get_reviews(app_list_df, country_code=\"de\"):\n",
    "    \"\"\"\n",
    "    This function returns a data frame including scraped reviews from the App store.\n",
    "    Parameters:\n",
    "    app_list_df - data frame including the app id and name (as displayed in the app store url).\n",
    "    country_code - 2-digit country code specifiying from which local app store the reviews should be scraped. \n",
    "    \"\"\"\n",
    "    app_names = app_list_df[\"iOS_app_name\"]\n",
    "    app_ids = app_list_df[\"iOS_app_id\"]\n",
    "    \n",
    "    # gather reviews for each app\n",
    "    for app_name, app_id in zip(app_names, app_ids):\n",
    "        \n",
    "        # get current time\n",
    "        start_time = dt.datetime.now(tz=get_localzone())\n",
    "        time_format = \"%m/%d/%y - %T %p\"\n",
    "        \n",
    "        # print starting of scraping app 1,...,n\n",
    "        print(\"----\"*20)\n",
    "        print(\"----\"*20)\n",
    "        print(f\"x-x-x-x-x-x {app_name} started at {start_time.strftime(time_format)}\")\n",
    "        \n",
    "        # initialize AppStore object\n",
    "        app_ = AppStore(country=country_code, app_name=app_name, app_id=app_id)\n",
    "        # get ALL reviews available for the app in the countries app store\n",
    "        app_.review(sleep=random.randint(5, 10))\n",
    "        \n",
    "        cur_reviews = app_.reviews\n",
    "        \n",
    "        # add meta information to review table\n",
    "        for review in cur_reviews:\n",
    "            review[\"app_name\"] = app_name\n",
    "            review[\"app_id\"] = app_id\n",
    "            \n",
    "        # print ending of scraping app 1,...,n\n",
    "        print(f\"Done scraping {app_name}. Scraped {app_.reviews_count} reviews.\")\n",
    "        \n",
    "        # convert to data frame and write to csv\n",
    "        review_df = pd.DataFrame(cur_reviews)\n",
    "        review_df.to_csv(\"reviews_\" + app_name + \".csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "        # provide finishing message\n",
    "        end_time = dt.datetime.now(tz=get_localzone())\n",
    "        print(f\"Wrote {app_name} reviews to csv at {end_time.strftime(time_format)}.\")\n",
    "        print(f\"Required time for {app_name}: {end_time-start_time}\")\n",
    "        \n",
    "        # wait a few seconds before starting with the next app\n",
    "        time.sleep(random.randint(5, 10))\n",
    "\n",
    "        \n",
    "def read_and_merge_reviews():\n",
    "    \"\"\"\n",
    "    Returns a data frame that contains all the merged reviews scraped from the app store.\n",
    "    \"\"\"\n",
    "    all_files = os.listdir()\n",
    "    review_files = [review for review in all_files if \"reviews_\" in review]\n",
    "    df = pd.concat(map(pd.read_csv, review_files)).reset_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_labels(x, y):\n",
    "    \"\"\"\n",
    "    Add centered labels to plot\n",
    "    \"\"\"\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], y[i], ha = 'center')\n",
    "\n",
    "\n",
    "def plot_bar_from_group(grouped_data, title, xlabel, ylabel):\n",
    "    \"\"\"\n",
    "    Plot the count of each grouped class in a bar graph.\n",
    "    \"\"\"\n",
    "    cust_dict = {\n",
    "        \"group_label\": list(grouped_data.index),\n",
    "        \"count\": list(grouped_data.values)\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(cust_dict)\n",
    "    df = df.sort_values(by=\"count\").reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(df[\"group_label\"], df[\"count\"])\n",
    "    add_labels(df[\"group_label\"], df[\"count\"])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.savefig('average_rating_written_feeback_only.png', bbox_inches = \"tight\")\n",
    "    plt.show()   \n",
    "    \n",
    "    \n",
    "def convert_to_datetime(date_col):\n",
    "    \"\"\"\n",
    "    Return converted datetime object based on date_col string input.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for date in date_col:\n",
    "        converted_date = dt.datetime.strptime(date, \"%Y-%m-%d %H:%M:%S\")\n",
    "        out.append(converted_date)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def lemmatization(texts, allowed_postags=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    \"\"\"\n",
    "    This function applies lemmatization to the list of reviews passed as input. \n",
    "    Lemmatization reduces words to its stem i.e. talked, talking, talk -> talk.\n",
    "    Additionally, the nlp() basic preprocessing is applied. i.e. lower case, removal of numbers/special characters.\n",
    "    \n",
    "    Returns a cleaned/lemmatized list of reviews.\n",
    "    \"\"\"\n",
    "    nlp = spacy.load(\"de_core_news_sm\", disable=[\"parser\", \"ner\"])  \n",
    "    texts_out = []\n",
    "    for text in texts:\n",
    "        document = nlp(text)\n",
    "        # iterate over each token in the document\n",
    "        new_text = []\n",
    "        for token in document:\n",
    "            if token.pos_ in allowed_postags:\n",
    "                new_text.append(token.lemma_)\n",
    "        merged_lemma_sentence = \" \".join(new_text)\n",
    "        texts_out.append(merged_lemma_sentence)\n",
    "    return texts_out\n",
    "\n",
    "\n",
    "def generate_word_tokens(texts):\n",
    "    \"\"\"\n",
    "    Generates a list of seperated words for each review. Additonally, applies lower case to remove semantic redundancy.\n",
    "    \"\"\"\n",
    "    processed_reviews = []\n",
    "    for text in texts:\n",
    "        new_text = gensim.utils.simple_preprocess(text, deacc=True)\n",
    "        processed_reviews.append(new_text)\n",
    "    return processed_reviews\n",
    "\n",
    "\n",
    "def create_dict_and_corpus(data_words):\n",
    "    \"\"\"\n",
    "    Generates: 1. A word dictionary \n",
    "               2. A corpus\n",
    "    \"\"\"\n",
    "    # create translation dictionary\n",
    "    id2word = corpora.Dictionary(data_words)\n",
    "    # create corpus\n",
    "    corpus = []\n",
    "    for review in data_words:\n",
    "        new_review = id2word.doc2bow(review)\n",
    "        corpus.append(new_review)\n",
    "        \n",
    "    return id2word, corpus\n",
    "\n",
    "\n",
    "\n",
    "def compute_coherence_score(k_start, k_max, steps, id2word, corpus, text):\n",
    "    \"\"\"\n",
    "    Estimate a LDA model for the range of topics and evaluate its coherence scores.\n",
    "    \"\"\"\n",
    "    coherence_scores = []\n",
    "    models = []\n",
    "    for num_topics in range(k_start, k_max, steps):\n",
    "        cur_lda = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                                 id2word=id2word,\n",
    "                                                 num_topics=num_topics,\n",
    "                                                 random_state=42,\n",
    "                                                 update_every=1,\n",
    "                                                 chunksize=100,\n",
    "                                                 passes=10,\n",
    "                                                 alpha=\"auto\")\n",
    "        models.append(cur_lda)\n",
    "        coherence_model = CoherenceModel(model=cur_lda, texts=text, dictionary=id2word, coherence=\"c_v\")\n",
    "        coherence_scores.append(coherence_model.get_coherence())\n",
    "    return models, coherence_scores\n",
    "\n",
    "\n",
    "\n",
    "def remove_junk(texts, stops):\n",
    "    \"\"\"\n",
    "    This function takes a review as input and does the following:\n",
    "    1.) remove german stopwords\n",
    "    2.) remove punctiation\n",
    "    3.) remove numbers\n",
    "    4.) remove unnessary white space\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"\\d+\", \"\", texts)\n",
    "    words = texts.split()\n",
    "    final = []\n",
    "    for word in words:\n",
    "        # remove stop words\n",
    "        if word not in stops:\n",
    "            final.append(word)\n",
    "    final = \" \".join(final)\n",
    "    # remove punctuation\n",
    "    final = final.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # remove numbers\n",
    "    final = \"\".join([i for i in final if not i.isdigit()])\n",
    "    # remove double whitespace\n",
    "    while \"  \" in final:\n",
    "        final = final.replace(\"  \", \" \")\n",
    "    return final\n",
    "\n",
    "\n",
    "def clean_document(docs):\n",
    "    \"\"\"\n",
    "    This function applies the remove_junk function to a list of reviews\n",
    "    \"\"\"\n",
    "    stops = stopwords.words(\"german\")\n",
    "    final = []\n",
    "    for doc in docs:\n",
    "        clean_doc = remove_junk(doc, stops)\n",
    "        final.append(clean_doc)\n",
    "    return final\n",
    "\n",
    "\n",
    "def format_topics_sentences(lda_model, corpus, review_df):\n",
    "    \"\"\"\n",
    "    This function returns the review_df data frame with the additinal feaatures of:\n",
    "    1.) Dominant topic\n",
    "    2.) Perc. Contribution of Dominant Topic\n",
    "    3.) Top Keywords Associated to Topic i\n",
    "    \"\"\"\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(lda_model[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = lda_model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "\n",
    "    sent_topics_df = pd.concat([sent_topics_df, review_df], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "def investigate_top_perc_contribution(df):\n",
    "    \"\"\"\n",
    "    Takes the review data frame that includes dominant topic as an input.\n",
    "    Returns one sentence for each topic that has the highest percentual contibution.\n",
    "    Thus, gives examples of what sentencs that describe the certain topic look like.\n",
    "    \"\"\"\n",
    "    output = pd.DataFrame()\n",
    "    grouped_df = df.groupby(\"Dominant_Topic\")\n",
    "    \n",
    "    for i, group in grouped_df:\n",
    "        output = pd.concat([output, group.sort_values([\"Perc_Contribution\"], ascending=False).head(1)], axis=0)\n",
    "        \n",
    "    output.reset_index(drop=True, inplace=True)\n",
    "    return output\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4d4e5a-6ff0-48b3-8473-d94cc9c8b7d3",
   "metadata": {},
   "source": [
    "### Apply all relevant functions and gather review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5351688-2114-4110-8c51-25438fd626a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load app list\n",
    "app_list_df = load_app_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a9aa2-97e2-4024-9055-36ff3a40f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba319c0b-440e-42f6-9083-bd6936191d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get meta app information\n",
    "meta_app_df = get_general_app_info(app_list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc542e2b-f634-4f84-83c6-fdc7d830c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_app_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708860d7-89c7-4ff3-9d76-9462eada82c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append app name to meta data\n",
    "meta_app_df[\"app_name\"] = app_list_df[\"app_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc5cce-a420-41c9-8d88-88eb24674b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rating to log scale\n",
    "meta_app_df[\"log_userRatingCount\"] = meta_app_df[\"userRatingCount\"].apply(lambda x: math.log(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66610fe1-7aa5-4f2c-b73e-b8bfc939087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot app meta information for global market\n",
    "fig = plt.figure(figsize=(10,6), dpi=1200)\n",
    "ax = fig.add_subplot(111)\n",
    "ax2 = ax.twinx()\n",
    "width = 0.3\n",
    "x = meta_app_df[\"app_name\"]\n",
    "meta_app_df[\"userRatingCount\"].plot(kind='bar', color='red', ax=ax, width=width, position=1, label=\"Number of reviews\")\n",
    "meta_app_df[\"averageUserRating\"].plot(kind='bar', color='blue', ax=ax2, width=width, position=0, label=\"Average Rating\")\n",
    "ax.set_ylabel('Number of reviews')\n",
    "ax2.set_ylabel('Average Rating')\n",
    "ax.set_xlabel(\"Application\")\n",
    "#ax.legend(loc=\"upper left\")\n",
    "#ax2.legend(loc=\"upper right\")\n",
    "\n",
    "\n",
    "ax.set_xticklabels(x, rotation=45)\n",
    "\n",
    "rects_one = ax.patches\n",
    "rects_two = ax2.patches\n",
    "\n",
    "# add labels for ax 1\n",
    "for rect, value in zip(rects_one, meta_app_df[\"userRatingCount\"]):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height + 5, value, ha=\"center\", va=\"bottom\", size=7)\n",
    "    \n",
    "\n",
    "for rect_2, value_2 in zip(rects_two, meta_app_df[\"averageUserRating\"]):\n",
    "    height_2 = rect_2.get_height()\n",
    "    ax2.text(rect_2.get_x() + rect_2.get_width() / 2, height_2 , str(round(value_2, 1)), ha=\"center\", va=\"bottom\", size=7)\n",
    "\n",
    "plt.savefig('aggregate_valence_volume_landingpage.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e58f95-06a7-4f7a-a8ec-94f7c06894e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape and write reviews to csv in working directory (Initial Scraping Date: 23.06.2022)\n",
    "get_reviews(app_list_df, country_code=\"de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f74e11-2819-483d-a380-fb9b39c3662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and merge all scraped reviews\n",
    "review_df = read_and_merge_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d1229-43cf-4550-a0fa-3d0a10c28138",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124df77c-4a64-4b1b-bac7-0d912bffaf5b",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafa44a-3128-4167-9dc6-cb2de61f2e37",
   "metadata": {},
   "source": [
    "How many reviews are available in the german App Store per application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0224768-0ff9-4713-bb3c-bd749ba7a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate number of reviews per application\n",
    "plt.rcParams[\"figure.dpi\"] = 1200\n",
    "review_count_by_app = review_df.groupby(\"app_name\")[\"review\"].size()\n",
    "\n",
    "# plot number of reviews per application\n",
    "plot_bar_from_group(review_count_by_app,\n",
    "                   xlabel=\"App Name\",\n",
    "                   ylabel=\"Number of reviews\",\n",
    "                   title=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c829cfd-9439-47cc-9612-52b4e7bb119f",
   "metadata": {},
   "source": [
    "What is the average rating per app?\n",
    "<p>Important finding: Average ratings and number of reviews displayed in the App Store represent global submissions.\n",
    "However, when we narrow down to the german market only, we obtain a differrent picture.\n",
    "The number and average rating of the My Porsche App was verified by visting the German App Store and manually scanning the reviews. Thus, for all of the apps, we observe a worse satisfaction level in Germany, compared to the global perception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ecfec0-38dd-424e-82b0-d20668b30dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average rating by application\n",
    "average_rating_by_app = review_df.groupby(\"app_name\")[\"rating\"].mean().round(1)\n",
    "\n",
    "# plot average rating per application\n",
    "plot_bar_from_group(average_rating_by_app,\n",
    "                   title=\"\",\n",
    "                   xlabel=\"App Name\",\n",
    "                   ylabel=\"Average Rating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc35128d-889d-4011-9880-f47b378830a2",
   "metadata": {},
   "source": [
    "How are the ratings distributed by app?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec72b36a-9926-41c5-94c6-e8e9c78eea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot rating distribution by app\n",
    "plt.rcParams[\"figure.dpi\"] = 1200\n",
    "ax = (review_df[[\"app_name\", \"rating\"]].groupby(['app_name','rating'])\n",
    "   .value_counts().unstack('rating').plot.bar(figsize=(10,5), rot=45))\n",
    "ax.set_xlabel(\"App\")\n",
    "ax.set_ylabel(\"Number of reviews\")\n",
    "ax.set_title(\"Distribution of ratings by app\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534c069-5b44-4eb7-8bf3-95fb5796238c",
   "metadata": {},
   "source": [
    "How many reviews did users submit over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d744919-27ad-4607-8a9f-2ad027db94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date feature to datetime object\n",
    "review_df[\"date\"] = convert_to_datetime(review_df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178768c-0e55-4caa-b17f-9a44ed24d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a year-month column\n",
    "review_df[\"year_month\"] = review_df[\"date\"].dt.to_period(\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f703dc-6602-412c-b368-6eac464d7fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot monthly number of reviews by app\n",
    "plt.rcParams[\"figure.dpi\"] = 1200\n",
    "ax = (review_df[[\"app_name\", \"year_month\"]].groupby(['app_name','year_month'])\n",
    "   .value_counts().unstack('app_name').plot(figsize=(10,6), rot=45, style=\".-\"))\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Number of reviews\")\n",
    "plt.legend(title=\"Application\")\n",
    "plt.savefig(\"development_of_review_volume_over_time.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed420d-e619-4f6c-b738-473ebf868f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get minimum date for first reviw with written feedback per app\n",
    "review_df.groupby(\"app_name\")[\"date\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81a164-833c-4d8b-a19e-b5250104b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get launch difference between first written review and scraping data\n",
    "scraping_date = \"2022-06-23\"\n",
    "scraping_date = dt.datetime.strptime(scraping_date, \"%Y-%m-%d\")\n",
    "min_date_by_app = review_df.groupby(\"app_name\")[\"date\"].min()\n",
    "print(min_date_by_app)\n",
    "days_since_first_review = []\n",
    "for date in min_date_by_app:\n",
    "    date_diff = (scraping_date - date).days\n",
    "    days_since_first_review.append(date_diff)\n",
    "    \n",
    "print(days_since_first_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dac205-b21b-4e14-a50e-3bccae589759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"My Porsche Reviews per day: {round(218/253, 1)}\")\n",
    "print(f\"My BMW Reviews per day: {round(58699/695, 1)}\")\n",
    "print(f\"My Audi Rviews per day: {round(16442/4029, 1)}\")\n",
    "print(f\"MINI Reviews per day: {round(6575/695, 1)}\")\n",
    "print(f\"FordPass Reviews per day: {round(16472/2065, 1)}\")\n",
    "print(f\"Mercedes Me Reviews per day: {round(83176/702, 1)}\")\n",
    "print(f\"Volkswagen We Connect Reviews per day: {round(30113/3130, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3393ba-5cf7-4305-8c4b-9fb72f7ac6e4",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446bf41-3343-4790-a0fb-106a08860222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample equal number of reviews per app (with same rating weight as observed in full set)\n",
    "review_subset = review_df.groupby(\"app_name\").apply(lambda x: x.sample(80, random_state=666, weights=review_df.groupby('app_name')[\"rating\"].transform('count'))).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b35d44-4e0b-4faf-a2bd-a3ef6e878f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b807b-abd1-4a6d-879e-faed5e79ebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare average rating with average rating of full data\n",
    "review_subset.groupby(\"app_name\")[\"rating\"].mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b6cae-8ad8-4bcc-b6ab-1ddf688ff1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify 560 total observations (80*n_brands)\n",
    "review_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb60074-ff13-42de-83d4-b2a4f4cdb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply lemmatization (reduce word to its root-stem)\n",
    "lemmatized_reviews = lemmatization(review_subset[\"review\"])  # exchange review_subset with review_df[\"review\"] to get full data as model input\n",
    "# apply custom text cleaning\n",
    "lemmatized_reviews = clean_document(lemmatized_reviews) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dbed0f-bfc9-4bce-9633-6b4eef20db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "data_words = generate_word_tokens(lemmatized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98877c8-e9a4-4b65-affa-9e86b83a87a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60d1b5-65da-4c19-af4f-aa60e4416308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index to word dictionary (required for LDA modeling)\n",
    "id2word, corpus = create_dict_and_corpus(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a215744-1eaa-4062-a549-05ea7a285c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of tuples: (i, j) -> i = index of word in dictionary, j = frequency of word at index i\n",
    "print(corpus[0][0:10])\n",
    "print(f\"Word of first tuple: {id2word[[0][:1][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27243f86-b7d9-4adf-b7ca-eefecb281812",
   "metadata": {},
   "source": [
    "## Additional Preprocessing - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37245ea6-8f1b-4c61-bb7b-c0404872f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new id2word dictionay and corpus based on bi/trigram tokenized data\n",
    "id2word_iter = corpora.Dictionary(data_words)\n",
    "texts_iter = data_words\n",
    "corpus_iter = [id2word_iter.doc2bow(text) for text in texts_iter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba5c91-6e20-4227-87c7-256a6d0575fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize TF-IDF object (goal: exclude overly-used/non specific words)\n",
    "tfidf = TfidfModel(corpus_iter, id2word_iter)\n",
    "\n",
    "low_value = 0.05\n",
    "words = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in range(0, len(corpus_iter)):\n",
    "    bow = corpus_iter[i]\n",
    "    low_value_words = []\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_value_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_value_words + words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word_iter[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "    \n",
    "    new_bow = [b for b in bow if b[0] not in low_value_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus_iter[i] = new_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52f375-730b-4ee9-b266-e34206ac5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique list of words to be filtered out\n",
    "unique_words_filter_out = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ebae0-e78b-44f7-bf8f-fa32411796fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_words_filter_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87569323-0fde-4784-9466-6557819a8117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove threhold words\n",
    "removed_tfidf_reviews = []\n",
    "for review in data_words:\n",
    "    cur_review = review\n",
    "    updated_review = [word for word in cur_review if word not in unique_words_filter_out]\n",
    "    removed_tfidf_reviews.append(updated_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299989df-6753-4745-97f3-6a01c91e54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(removed_tfidf_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a66b6f-ae6c-4075-9dcc-3d6e659f5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(removed_tfidf_reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fa9be-15a3-4c01-b3e4-e664078bc861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out custom removal words (Iterative Process based on earlier iterations of the LDA Topic Modeling Output)\n",
    "custom_removal_words = [\"zb\", \"danke\", \"etc\", \"wohl\", \"warum\", \"einfach\", \"erst\", \"wirklich\", \"somit\", \"groß\", \"dabei\", \"usw\", \"bitte\", \"tun\", \"allerdings\", \"ganz\", \"standheizung\",\"fahrtenbuch\" ,\"ja\", \"sehen\", \"lange\", \"alt\"]\n",
    "reviews_cleaned = []\n",
    "for review in removed_tfidf_reviews:\n",
    "    new_review = [word for word in review if word not in custom_removal_words]\n",
    "    reviews_cleaned.append(new_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48049103-c8c0-4466-8dd3-3991eb47f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reviews_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04542286-754b-4a40-a67f-707cae8ea93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(removed_custom_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf95894-3098-422e-b7be-f0da41b2c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently with reviews_cleaned\n",
    "id2word_updated = corpora.Dictionary(reviews_cleaned)  # to revert to initial replace with removed_tfidf_reviews\n",
    "corpus_updated = [id2word_updated.doc2bow(text) for text in reviews_cleaned]  # to revert to initial replace with removed_tfidf_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50598f-9851-4cd1-8e09-1ac3495868a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate LDA with abitrary number of topic to see if it works on processed data. In this case 8\n",
    "lda_model_after_tfidf_removal = gensim.models.ldamodel.LdaModel(corpus=corpus_updated,\n",
    "                                                               id2word=id2word_updated,\n",
    "                                                               num_topics=8,\n",
    "                                                               random_state=42,\n",
    "                                                               update_every=1,\n",
    "                                                               chunksize=100,\n",
    "                                                               passes=10,\n",
    "                                                               alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e768e5-6265-40ea-b14d-fcd33bb63699",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim_models.prepare(lda_model_after_tfidf_removal, corpus_updated, id2word_updated, mds=\"mmds\", R=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d71dfe-97c5-48e1-9c98-476d7e8a0c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coherence score:\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_after_tfidf_removal, \n",
    "                                     texts=data_words, \n",
    "                                     dictionary=id2word_updated, \n",
    "                                     coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5fe3a7-29ef-4fef-8951-c41867e57d76",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd29c95c-e891-4fa3-8324-2d12249ebebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize topic space\n",
    "k_start = 2\n",
    "k_max = 9\n",
    "steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cb6d8f-4379-48ff-a42b-ed8dcb99d3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "models, coherence_scores = compute_coherence_score(k_start=k_start, \n",
    "                                                   k_max=k_max, \n",
    "                                                   steps=steps, \n",
    "                                                   id2word=id2word_updated, \n",
    "                                                   corpus=corpus_updated,\n",
    "                                                   text=data_words)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ea548-ffa1-4645-985b-a4aa69efc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot coherence scores\n",
    "x = list(range(k_start, k_max, steps))\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, coherence_scores)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.savefig('coherence_score.png', bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b7fb2-074b-4b32-99c4-7136268e03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coherence scores\n",
    "for topic_number, coherence in zip(x, coherence_scores):\n",
    "    print(\"Num Topics =\", topic_number, \" has Coherence Value of\", round(coherence, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629776e-8e16-4016-87da-27bb7108824b",
   "metadata": {},
   "source": [
    "The coherence score is maximized at num_topics = 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae47676-2a6a-4450-afca-1290dabfd564",
   "metadata": {},
   "source": [
    "## Final LDA Model with n_topics = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a797d2-71b3-4160-a874-13adea3b3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lda = gensim.models.ldamodel.LdaModel(corpus=corpus_updated,\n",
    "                                                               id2word=id2word_updated,\n",
    "                                                               num_topics=6,\n",
    "                                                               random_state=42,\n",
    "                                                               update_every=1,\n",
    "                                                               chunksize=100,\n",
    "                                                               passes=10,\n",
    "                                                               alpha=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f881d8-f113-496e-900e-10bf1c6e438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT NOTE: LDAvis Topic numbering does NOT correspond to actual Topic numbering (see below for accurate.)\n",
    "# This is just an interactive view on how destinguishable the topics are\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim_models.prepare(final_lda, corpus_updated, id2word_updated, mds=\"mmds\", R=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c4c61-d1a6-4c97-b7db-e6cbd79ea1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud of keywords in Topics (https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/)\n",
    "# 1. Wordcloud of Top N words in each topic\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]  # more colors: 'mcolors.XKCD_COLORS'\n",
    "\n",
    "cloud = WordCloud(stopwords=stopwords.words(\"german\"),\n",
    "                  background_color='white',\n",
    "                  width=2500,\n",
    "                  height=1800,\n",
    "                  max_words=10,\n",
    "                  colormap='tab10',\n",
    "                  color_func=lambda *args, **kwargs: cols[i],\n",
    "                  prefer_horizontal=1.0)\n",
    "\n",
    "topics = final_lda.show_topics(formatted=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(13,13), sharex=True, sharey=True)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    fig.add_subplot(ax)\n",
    "    topic_words = dict(topics[i][1])\n",
    "    cloud.generate_from_frequencies(topic_words, max_font_size=300)\n",
    "    plt.gca().imshow(cloud)\n",
    "    plt.gca().set_title('Topic ' + str(i), fontdict=dict(size=16))\n",
    "    plt.gca().axis('off')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "plt.axis('off')\n",
    "plt.margins(x=0, y=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66cbab-2dea-499a-ae4b-4a35335c1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#19findthemostrepresentativedocumentforeachtopic\n",
    "# Visalize top keywords\n",
    "\n",
    "from collections import Counter\n",
    "topics = final_lda.show_topics(formatted=False)\n",
    "data_flat = [w for w_list in reviews_cleaned for w in w_list]  # replace \"reviews_cleaned\" with removed_tfidf_reviews to revert to original layout\n",
    "counter = Counter(data_flat)\n",
    "\n",
    "out = []\n",
    "for i, topic in topics:\n",
    "    for word, weight in topic:\n",
    "        out.append([word, i , weight, counter[word]])\n",
    "\n",
    "df = pd.DataFrame(out, columns=['word', 'topic_id', 'importance', 'word_count'])        \n",
    "\n",
    "# Plot Word Count and Weights of Topic Keywords\n",
    "fig, axes = plt.subplots(2, 3, figsize=(30,18), sharey=True, dpi=600)\n",
    "cols = [color for name, color in mcolors.TABLEAU_COLORS.items()]\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.bar(x='word', height=\"word_count\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.5, alpha=0.3, label='Word Count')\n",
    "    ax_twin = ax.twinx()\n",
    "    ax_twin.bar(x='word', height=\"importance\", data=df.loc[df.topic_id==i, :], color=cols[i], width=0.2, label='Weights')\n",
    "    ax.set_ylabel('Word Count', color=cols[i])\n",
    "    ax_twin.set_ylim(0, 0.030); ax.set_ylim(0, 200)\n",
    "    ax.set_title('Topic: ' + str(i), color=cols[i], fontsize=16)\n",
    "    ax.tick_params(axis='y', left=False)\n",
    "    ax.set_xticklabels(df.loc[df.topic_id==i, 'word'], rotation=30, horizontalalignment= 'right')\n",
    "    ax.legend(loc='upper left'); ax_twin.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout(w_pad=2)    \n",
    "fig.suptitle('', fontsize=22, y=1.05)\n",
    "             \n",
    "plt.savefig(\"LDA_wordfrequencies_and_weights.png\", bbox_inches=\"tight\")           \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325832d8-f5fd-4078-8bc0-55a3db4e3434",
   "metadata": {},
   "source": [
    "### Naming Topics (Subjective but whatever :D):\n",
    "Takes into consideration the wordcloud/frequency as well as the LDAvis output that shows top 30 relevant keywords.\n",
    "- <b> Topic 0 </b>\n",
    "<p>Missing Updates\n",
    "- <b> Topic 1 </b>\n",
    "<p> Connectivity Issues\n",
    "- <b> Topic 2 </b>\n",
    "<p> Time-based Support    \n",
    "- <b> Topic 3 </b>\n",
    "<p> Legacy Systems\n",
    "- <b> Topic 4 </b>\n",
    "<p> Application Error\n",
    "- <b> Topic 5 </b>\n",
    "<p>Legacy Connectivity\n",
    "- <b> Topic 6 </b>\n",
    "<p> Useability and Activation\n",
    "- <b> Topic 7 </b>\n",
    "<p> Loading and Login Service    \n",
    "- <b> Topic 8 </b>\n",
    "<p> Feature Availibility\n",
    "- <b> Topic 9 </b>\n",
    "<p> Access Error Support Request\n",
    "    \n",
    "-------- UPDATED TOPICS WITH REMOVED CUSTOM WORDS (n_num=6)\n",
    "- <b> Topic 0 </b>\n",
    "<p>Error Message for Sign-Up & Update Service\n",
    "- <b> Topic 1 </b>\n",
    "<p> Customizability\n",
    "- <b> Topic 2 </b>\n",
    "<p> Slow Updates   \n",
    "- <b> Topic 3 </b>\n",
    "<p> Connectivity Problems\n",
    "- <b> Topic 4 </b>\n",
    "<p> Time-based Charging\n",
    "- <b> Topic 5 </b> \n",
    "<p> Missing Feature "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5076d-6946-4fa5-9532-eb1b227134d4",
   "metadata": {},
   "source": [
    "## Find the dominant topic in each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31670879-71e8-43c1-ba30-409919e89d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_topics = format_topics_sentences(final_lda, corpus_updated, review_subset)  # exchange review_subset with review_df for entire data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c9b6f-115f-4c01-8d51-437d376d9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dictionary = {0: \"Missing Update\",\n",
    "                  1:  \"Connectivity Issue\",\n",
    "                  2:  \"Time-based Support\",\n",
    "                  3:  \"Legacy Systems\",\n",
    "                  4:  \"Application Error\",\n",
    "                  5:  \"Legacy Connectivity\", \n",
    "                  6:  \"Usability & Activation\",\n",
    "                  7:  \"Loading & Login Service\",\n",
    "                  8:  \"Feature Availibility\",\n",
    "                  9:  \"Access Error Support Request\"}\n",
    "\n",
    "\n",
    "name_dictionary_new = {0: \"Error Message for Signup & Update Service\",\n",
    "                  1:  \"Customizability\",\n",
    "                  2:  \"Slow Updates\",\n",
    "                  3:  \"Connectivity Problems\",\n",
    "                  4:  \"Time-based Charging\",\n",
    "                  5:  \"Missing Feature\"} \n",
    "                    \n",
    "    \n",
    "\n",
    "def add_topic_name(name_dictionary, df):  \n",
    "    topic_name = []\n",
    "    for topic_number in df[\"Dominant_Topic\"]:\n",
    "        topic_name.append(name_dictionary.get(topic_number))\n",
    "    \n",
    "    topic_name = pd.Series(topic_name)\n",
    "    return topic_name\n",
    "    \n",
    "    \n",
    "df_with_topics[\"Topic_Name\"] = add_topic_name(name_dictionary_new, df_with_topics)   # replace name_dictionary_new with name_dictionary to revert to old results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f4ea8b-8667-449c-b49b-0f2bd97f7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790873d-7d4b-4606-ba1d-4ed96d41f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_with_topics[\"Dominant_Topic\"])  # 0 -> Topic 1 etc. Apparently topic 2 is NOT the most dominant in any case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22bfb56-6c0d-4aa1-a557-4bfb8b488701",
   "metadata": {},
   "source": [
    "## Plot distribution of Topics by App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460f911-61ef-4082-a043-13646e3a2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of topics by app\n",
    "ax = (df_with_topics[[\"app_name\", \"Topic_Name\"]].groupby(['app_name','Topic_Name'])\n",
    "   .value_counts().unstack('Topic_Name').plot.bar(figsize=(10,8), rot=45))\n",
    "ax.set_xlabel(\"Application\")\n",
    "ax.set_ylabel(\"Number of Topic occurences\")\n",
    "ax.set_title(\"\")\n",
    "plt.savefig(\"Distribution_of_topics_by_app.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12483db5-1992-46ec-9015-94dad863be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_with_topics[[\"app_name\", \"Topic_Name\"]].groupby([\"app_name\", \"Topic_Name\"]).value_counts() / 80*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ef2e3-89f8-4df9-8bda-8d3e4e5043c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get percentages\n",
    "ax = (df_with_topics[[\"app_name\", \"Topic_Name\"]].groupby([\"app_name\", \"Topic_Name\"]).value_counts() / 80*100).unstack(\"Topic_Name\").plot.bar(figsize=(10,8), rot=45)\n",
    "ax.set_xlabel(\"Application\")\n",
    "ax.set_ylabel(\"Percentage of topic occurence within application\")\n",
    "ax.set_title(\"\")\n",
    "fmt = '%.0f%%' # Format you want the ticks, e.g. '40%'\n",
    "yticks = mtick.FormatStrFormatter(fmt)\n",
    "ax.yaxis.set_major_formatter(yticks)\n",
    "plt.legend(title=\"Topic Name\")\n",
    "plt.savefig(\"Percentage_of_topics_by_app.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c470a94-4173-47aa-b07d-b13bdd7da3d7",
   "metadata": {},
   "source": [
    "### What is the average rating by app and Topic. Do some apps perform better within certain categories?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f3633f-2257-467f-bdd6-e5fdfa54a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with getting averge rating by topic for porsche\n",
    "porsche_topics_subset = df_with_topics[df_with_topics[\"app_name\"] == \"my-porsche\"]\n",
    "\n",
    "# plot average rating by topic\n",
    "porsche_topics_subset.groupby(\"Topic_Name\")[\"rating\"].mean().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a1190-5a9b-4b91-9602-48915b41035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get average rating by topic per app\n",
    "ax = df_with_topics.groupby([\"app_name\", \"Topic_Name\"])[\"rating\"].mean().unstack(\"Topic_Name\").plot(kind=\"bar\", figsize=(10,8), rot=45)\n",
    "ax.set_xlabel(\"App\")\n",
    "ax.set_ylabel(\"Average Rating\")\n",
    "ax.set_title(\"\")\n",
    "plt.legend(title=\"Topic Name\")\n",
    "plt.savefig(\"averageRating_of_topics_by_app.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef5185-0c52-4099-ba70-7dd50f3de52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output percentual topic probabilities per review (one list entry = 1 review)\n",
    "for i, row in enumerate(final_lda[corpus_updated]):\n",
    "    row = sorted(row, key=lambda x:x[1], reverse=True)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82855b-82e8-42f6-943a-6f409447a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract top sentences that have a high percentual contribution in the corresponding topic\n",
    "top_sentences = investigate_top_perc_contribution(df_with_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6fd418-a0f8-4b0d-b403-4d42ebcb81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display exemplary sentneces for each topic (+1 index)\n",
    "for index, review in enumerate(top_sentences[\"review\"]):\n",
    "    print(f\"Topic {index+1}:\\n {review}\")\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1d20b-8083-48cd-91d5-80225d1fa102",
   "metadata": {},
   "source": [
    "## Try TF-IDF and KMeans approach to cluster short text into topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d31248-a318-4814-82dd-89486f5019c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply cleaning functions to raw text reviews\n",
    "clean_reviews = clean_document(lemmatized_reviews)  # basically redundant as already performed earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807e172-156e-4c14-ac4f-5153cbff0bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True,\n",
    "                            max_features=100,\n",
    "                            max_df=0.75,  # words that occur at greater than 75% in the corpus are ignored\n",
    "                            min_df=5,  # if a word does not occur at least 5 times, ignore it\n",
    "                            ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0d642-325d-4d30-8437-e74db2628f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply TF-IDF\n",
    "vectors = vectorizer.fit_transform(clean_reviews)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "\n",
    "all_keywords = []\n",
    "for description in denselist:\n",
    "    x = 0\n",
    "    keywords = []\n",
    "    for word in description:\n",
    "        if word > 0:\n",
    "            keywords.append(feature_names[x])\n",
    "        x += 1\n",
    "    all_keywords.append(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b7f58-39f8-4591-a31d-a899678bbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_keywords[0])\n",
    "print(\"--------\")\n",
    "print(clean_reviews[0])  # altered for TF-IDF approach --> Keywords of the revieew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87855918-2e0b-41a5-98ca-624843abf5f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cluster the list of keywords based on TF-IDF by KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40235d70-dbc6-493f-8446-9f3c03d3517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal number of clusters (initially using the elbow criterion)\n",
    "distortions = []\n",
    "K = range(1, 20)\n",
    "for k in K:\n",
    "    kmean_model = KMeans(n_clusters=k, init=\"k-means++\", max_iter=100, n_init=1)\n",
    "    kmean_model.fit(vectors)\n",
    "    distortions.append(kmean_model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b88bbb-afeb-4caf-8bae-5a92c346044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distortions = sum of squared distance between each observation vector\n",
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(list(K), distortions, \"bx-\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Distortion\")\n",
    "plt.title(\"Elbow Method showing the optimal number of clusters k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6397730f-9ce9-47c8-a7ed-69e4ebb42b2c",
   "metadata": {},
   "source": [
    "Based on this we can conclude that K = 10 is the seems appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8839ee94-370b-49a9-acaa-5573a168b035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit final Kmeans with k = 10\n",
    "final_kmeans = KMeans(n_clusters=10,\n",
    "                     init=\"k-means++\",\n",
    "                     max_iter=100,\n",
    "                     n_init=1)\n",
    "final_kmeans.fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d910e-4736-4ee0-b891-414c44322bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract information\n",
    "order_centroids = final_kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e9461-25db-4b5d-b00f-d6bffd73e3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print topic keywords that are associated with each cluster\n",
    "for i in range(8):\n",
    "    print(f\"Cluster {i}\")\n",
    "    print(\"\\n\")\n",
    "    for ind in order_centroids[i, :15]:\n",
    "        print(\" %s\" %terms[ind],)\n",
    "    print(\"\\n\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fcabe-490a-44a4-bcc4-e4f333aa686e",
   "metadata": {},
   "source": [
    "In comparison to the LDA approach, topic modelling with TFIDF and KMeans does not seem to yield interpretable results. Furthmore, we observe a even greater topic overlap in comparison to the LDA soltution. Thus, we consider the LDA approach more feasible for the final interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fabea-3f17-4fcc-a92b-ce99e6d40a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TBC\n",
    "print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77f6b5-84cc-4029-a0da-a095353a0872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wwu_da2",
   "language": "python",
   "name": "wwu_da2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
